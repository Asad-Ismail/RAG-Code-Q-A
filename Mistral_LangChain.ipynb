{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "17412960",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip -q install git+https://github.com/huggingface/transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30b02fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tiktoken chromadb langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67a65732",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from git import Repo\n",
    "from langchain.document_loaders.generic import GenericLoader\n",
    "from langchain.document_loaders.parsers import LanguageParser\n",
    "from langchain.text_splitter import Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94b2e1b5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load\n",
    "loader = GenericLoader.from_filesystem(\n",
    "    \"/home/ec2-user/SageMaker/VegRD_APD_Fruit_Phenotyping/scripts\",\n",
    "    glob=\"**/*\",\n",
    "    suffixes=[\".py\"],\n",
    "    parser=LanguageParser(language=Language.PYTHON, parser_threshold=500),\n",
    ")\n",
    "documents = loader.load()\n",
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "131b00e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "130"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9e29638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(page_content='import numpy as np\\nimport os, sys\\nfrom collections import defaultdict\\nfrom get_data import get_images\\nimport re\\n\\ndef update_config(config_defaults,**kwargs):\\n    new_config = config_defaults.copy()\\n    for key, value in kwargs.items():\\n        if key in new_config:\\n            new_config[key] = value\\n        else:\\n            raise KeyError(f\"Unknown configuration key: {key}\")\\n    return new_config\\n\\n\\ndef pattern_exists_in_string(string, pattern=\"BLK\"):\\n    if re.search(pattern, string):\\n        return True\\n    else:\\n        return False\\n\\n\\n# A dictionary of projects and images\\nprojs = defaultdict(list)\\n\\nwith open(\"new_images.txt\", \"r\") as f:\\n    for l in f.readlines():\\n        l=l.strip()\\n        splitted= l.split(\"/\")\\n        projs[splitted[1]].append(l)\\n\\nfor k,v in projs.items():\\n    get_images(k,s3_bucket=\"model-deployment-automation\", files_to_copy=v)\\n    if pattern_exists_in_string(k,pattern=\"BLK\"):\\n        from config import blocky_config_defaults as config_defaults\\n        from blocky_peppers import *     \\n        new_config=update_config(config_defaults,img_path=os.path.join(\"filtered\",k),proj_dynamo=os.path.join(\"Pepper\",k),\\n                                save_path=os.path.join(\"results\",k),save_aws=True,aws_path=\"automated\")\\n        main(new_config)\\n    else:\\n       raise ValueError(f\"{k} models is not Implemented\")\\n', metadata={'source': '/home/ec2-user/SageMaker/VegRD_APD_Fruit_Phenotyping/scripts/automate.py', 'language': <Language.PYTHON: 'python'>})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c968aeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "254"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "python_splitter = RecursiveCharacterTextSplitter.from_language(\n",
    "    language=Language.PYTHON, chunk_size=2000, chunk_overlap=200\n",
    ")\n",
    "texts = python_splitter.split_documents(documents)\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c5920c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fbd0728f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/InstructorEmbedding/instructor.py:7: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
      "  from tqdm.autonotebook import trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load INSTRUCTOR_Transformer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.10/site-packages/torch/_utils.py:831: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_seq_length  512\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings import HuggingFaceInstructEmbeddings\n",
    "embeddings = HuggingFaceInstructEmbeddings(\n",
    "    query_instruction=\"Query about the code base: \",\n",
    "    model_kwargs = {'device': 'cpu'}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "314cbeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(texts, embeddings)\n",
    "retriever = db.as_retriever(\n",
    "    search_type=\"mmr\",  # Also test \"similarity\"\n",
    "    search_kwargs={\"k\": 8},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ee070f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.memory import ConversationSummaryMemory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c2f6e032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00e41c8403f4485f8220a63c9b151961",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "import torch\n",
    "\n",
    "model_id = \"mistralai/Mistral-7B-Instruct-v0.1\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "#model = model.half()\n",
    "#model=model.to(\"cuda\")\n",
    "pipe = pipeline(\"text-generation\", model=model, tokenizer=tokenizer, max_new_tokens=1000)\n",
    "llm = HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ce6efaf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model is on device: cpu\n",
      "Model data type: torch.float32\n"
     ]
    }
   ],
   "source": [
    "# To check the device and dtype\n",
    "# Get the first parameter of the model and check its device and dtype\n",
    "first_param = next(model.parameters())\n",
    "model_device = first_param.device\n",
    "model_dtype = first_param.dtype\n",
    "\n",
    "print(f\"Model is on device: {model_device}\")\n",
    "print(f\"Model data type: {model_dtype}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be9f6045",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First, we need to understand what the brain is. The brain is a complex organ that controls all the functions of the human body. It is responsible for thinking, feeling, moving, and even breathing.\n",
      "\n",
      "Now, imagine if we could measure the electrical activity of the brain while it is functioning. This would give us a better understanding of how the brain works and how it processes information. This is where electroencephalography (EEG) comes in.\n",
      "\n",
      "EEG is a technique used to measure the electrical activity of the brain using electrodes placed on the scalp. These electrodes pick up tiny electrical signals produced by the brain cells, which are then recorded and analyzed. By studying these signals, we can learn more about the brain's functions and how it processes information.\n",
      "\n",
      "EEG is a non-invasive procedure, which means it does not involve any surgery or needles. It is a safe and effective way to study the brain and its functions. EEG is used in a variety of settings, including hospitals, research labs, and even in the field of sports medicine to help athletes optimize their performance.\n"
     ]
    }
   ],
   "source": [
    "## Test LLM without Context\n",
    "\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "template = \"\"\"Question: {question}\n",
    "\n",
    "Answer: Let's think step by step.\"\"\"\n",
    "prompt = PromptTemplate.from_template(template)\n",
    "\n",
    "chain = prompt | llm\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "\n",
    "print(chain.invoke({\"question\": question}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "96fc3adc",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = ConversationSummaryMemory(\n",
    "    llm=llm, memory_key=\"chat_history\", return_messages=True\n",
    ")\n",
    "qa = ConversationalRetrievalChain.from_llm(llm, retriever=retriever, memory=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d712403",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n",
      "Setting `pad_token_id` to `eos_token_id`:2 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "question = \"How can I initialize a ReAct agent?\"\n",
    "result = qa(question)\n",
    "result[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ed0bd34",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"How is curved backbone of hot peppers calculated?\",\n",
    "    \"How to turn on/off visulaizations of phenotypes?\",\n",
    "    \"How to turn on/off visulaizations of detections and phenotypes of hot peppers lsit all methods?\",\n",
    "]\n",
    "\n",
    "for question in questions:\n",
    "    result = qa(question)\n",
    "    print(f\"-> **Question**: {question} \\n\")\n",
    "    print(f\"**Answer**: {result['answer']} \\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d97ac47",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
